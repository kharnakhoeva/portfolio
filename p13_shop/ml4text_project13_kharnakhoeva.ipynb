{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf575472",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da26639",
   "metadata": {},
   "source": [
    "**Дано:** интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других\n",
    "\n",
    "**Задача:** найти инструмент, который будет искать токсичные комментарии и отправлять их на модерацию - найти модель классификации комментариев на позитивные и негативные со значением метрики качества F1 >= 0.75\n",
    "\n",
    "**План:**\n",
    "1. Обзор данных\n",
    "2. Подготовка данных\n",
    "3. Обучение и тестирование моделей\n",
    "4. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5528456",
   "metadata": {},
   "source": [
    "## 1. Обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715346f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a801664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    comments = pd.read_csv('/Users/galina/Desktop/учёба/спринт 13. Машиное обучение для текстов/toxic_comments.csv') \n",
    "except:\n",
    "    comments = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410423fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "-----------------------------------------------------------------\n",
      "Дубликатов - 0\n",
      "-----------------------------------------------------------------\n",
      "Пропусков:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Соотношение в целевом признаке:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments.head(5))\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "comments.info()\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "\n",
    "print('Дубликатов -', comments.duplicated().sum())\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "\n",
    "print('Пропусков:')\n",
    "display(comments.isna().sum())\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "\n",
    "print('Соотношение в целевом признаке:')\n",
    "display(comments.toxic.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218d959",
   "metadata": {},
   "source": [
    "### Выводы по п.1. Обзор данных:\n",
    "1. В таблице 159 292 объектов. Пропусков нет, явных дубликатов нет\n",
    "2. Тексты комментариев на английском, есть лишние знаки типа \"\\nMore\\n \n",
    "2. В целевом признаке 90% объектов отрицательного класса, то есть в дальнейшем нужно будет учесть это\n",
    "3. Необходимо избавиться от столбца Unnamed, так как он фактически дублирует индексы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba0f03b",
   "metadata": {},
   "source": [
    "## 2. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e65160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляю столбец Unnamed:\n",
    "comments = comments.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9df3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ввожу функцию очищения текстов постов:\n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8510510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.14 s, sys: 27.9 ms, total: 3.17 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#очищаю тексты постов:\n",
    "comments['text'] = comments['text'].apply(clear_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe50dbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he matches this background colour i m se...      0\n",
       "2  hey man i m really not trying to edit war it s...      0\n",
       "3  more i can t make any real suggestions on impr...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b3ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ввожу функцию РОS-тэгирования слов:\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,               #прилагательное\n",
    "                \"N\": wordnet.NOUN,              #существительное\n",
    "                \"V\": wordnet.VERB,              #глагол\n",
    "                \"R\": wordnet.ADV                #наречие\n",
    "               }  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#ввожу функцию леммализации тектов постов:\n",
    "def lemm_text(text):\n",
    "    text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478dc551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 37s, sys: 1min 47s, total: 13min 25s\n",
      "Wall time: 13min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#леммализирую тексты постов:\n",
    "comments['text'] = comments['text'].apply(lemm_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51581c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits make under my userna...      0\n",
       "1  d aww he match this background colour i m seem...      0\n",
       "2  hey man i m really not try to edit war it s ju...      0\n",
       "3  more i can t make any real suggestion on impro...      0\n",
       "4  you sir be my hero any chance you remember wha...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3965587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделяю выборки в соотношении 80/10/10:\n",
    "features = comments.drop(['toxic'], axis=1) \n",
    "target = comments.toxic\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=.2, \n",
    "                                                                              random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "                                                                            target_valid, \n",
    "                                                                            test_size=.5,\n",
    "                                                                            random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6a02220",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433, 1)\n",
      "(127433,)\n",
      "(15929, 1)\n",
      "(15929,)\n",
      "(15930, 1)\n",
      "(15930,)\n"
     ]
    }
   ],
   "source": [
    "#смотрю размеры выборок:\n",
    "for i in [features_train, target_train, features_valid, target_valid, features_test, target_test]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc89ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля значений 1 в тренировочной выборке: 0.10166911239631807\n"
     ]
    }
   ],
   "source": [
    "#смотрю соотношение 1/0 в выборках на примере target_train:\n",
    "indices_1 = [i for i,x in enumerate(target_train) if x == 1]\n",
    "count_1 = len(indices_1)\n",
    "\n",
    "indices_0 = [i for i,x in enumerate(target_train) if x == 0]\n",
    "count_0 = len(indices_0)\n",
    "\n",
    "print('Доля значений 1 в тренировочной выборке:', len(indices_1) / (len(indices_1) + len(indices_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "329e4307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соотношение 1/0 в тренировочной выборке:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: toxic, dtype: float64\n",
      "\n",
      "(25912,)\n",
      "(25912,)\n"
     ]
    }
   ],
   "source": [
    "#уменьшаю кол-во 0 в выборках train:\n",
    "\n",
    "comments_train = comments.iloc[target_train.index]\n",
    "target_train_0 = comments_train[comments_train['toxic'] == 0]['toxic']\n",
    "target_train_1 = comments_train[comments_train['toxic'] == 1]['toxic']\n",
    "\n",
    "\n",
    "target_train_0_resample = target_train_0.sample(target_train_1.shape[0], random_state=12345)\n",
    "target_train_resample = pd.concat([target_train_0_resample, target_train_1])\n",
    "\n",
    "features_train_resample = comments.iloc[target_train_resample.index]\n",
    "\n",
    "features_train_resample, target_train_resample = shuffle(features_train_resample,\n",
    "                                                         target_train_resample,\n",
    "                                                         random_state=12345)\n",
    "\n",
    "features_train_resample = features_train_resample.text \n",
    "\n",
    "print('Соотношение 1/0 в тренировочной выборке:')\n",
    "print(target_train_resample.value_counts(normalize=True))\n",
    "print()\n",
    "print(features_train_resample.shape)\n",
    "print(target_train_resample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edec1a2",
   "metadata": {},
   "source": [
    "### Выводы по п.2. Подготовка данных:\n",
    "При подготовке данных:\n",
    "1. Удалила ненужный столбец\n",
    "2. Очистила тексты комментариев от ненужных знаков, леммализировала, убрала стоп-слова\n",
    "3. Сбалансировала данные в целевом признаке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e317d",
   "metadata": {},
   "source": [
    "## 3. Обучение и тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad783b",
   "metadata": {},
   "source": [
    "### 3.1. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213c31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d14fb04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/galina/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии = 0.76\n",
      "при параметрах {'lr__C': 5, 'lr__class_weight': 'balanced', 'lr__max_iter': 200, 'lr__random_state': 12345, 'lr__solver': 'newton-cg'}\n",
      "\n",
      "F1 логистической регрессии на валидации = 0.76\n",
      "\n",
      "финальный F1 логистической регрессии = 0.76\n",
      "CPU times: user 13.5 s, sys: 15.9 s, total: 29.4 s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english', sublinear_tf=True)), \n",
    "                     (\"lr\", LogisticRegression())])\n",
    "    \n",
    "parameters = {'lr__solver': ('liblinear', 'saga','newton-cg', 'lbfgs'),\n",
    "              'lr__C': (.1, 1, 5, 10),\n",
    "              'lr__random_state': ([12345]),\n",
    "              'lr__max_iter': ([200]),\n",
    "              'lr__class_weight': (['balanced'])} #ну я поставила, хотя он тут не нужен\n",
    "                                                  #я ж сама сбалансировала их\n",
    "                                                  #нужен на несбалансированных данных, но у меня не получается их подать в модель\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "lr_train_f1 = max(mts)\n",
    "\n",
    "print('F1 логистической регрессии =', round(lr_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "lr_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 логистической регрессии на валидации =', round(lr_valid_f1,2))\n",
    "print()\n",
    "\n",
    "#тестирование:\n",
    "predictions_test = gscv.predict(features_test.text)\n",
    "lr_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('финальный F1 логистической регрессии =', round(lr_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d1fa1",
   "metadata": {},
   "source": [
    "### 3.2. Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8612241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 дерева решений = 0.71\n",
      "при параметрах {'dtc__class_weight': 'balanced', 'dtc__max_depth': 24, 'dtc__random_state': 12345}\n",
      "\n",
      "F1 дерева решений на валидации = 0.62\n",
      "\n",
      "финальный F1 дерева решений = 0.61\n",
      "CPU times: user 4.25 s, sys: 1.1 s, total: 5.35 s\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"dtc\", DecisionTreeClassifier())])\n",
    "    \n",
    "parameters = {'dtc__max_depth': ([x for x in range(1, 25)]),\n",
    "              'dtc__random_state': ([12345]), \n",
    "              'dtc__class_weight': (['balanced'])}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train_resample, target_train_resample)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "dtc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 дерева решений =', round(dtc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "dtc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 дерева решений на валидации =', round(dtc_valid_f1,2))\n",
    "print()\n",
    "\n",
    "#тестирование:\n",
    "predictions_test = gscv.predict(features_test.text)\n",
    "dtc_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('финальный F1 дерева решений =', round(dtc_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b781990",
   "metadata": {},
   "source": [
    "### 3.3. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce4a7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 CatBoostClassifier = 0.87\n",
      "при параметрах {'cbc__class_weights': (1, 1), 'cbc__iterations': 200, 'cbc__verbose': False}\n",
      "\n",
      "F1 CatBoostClassifier на валидации = 0.72\n",
      "\n",
      "финальный F1 CatBoostClassifier = 0.72\n",
      "CPU times: user 1min 59s, sys: 2.84 s, total: 2min 1s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"cbc\", CatBoostClassifier())])\n",
    "    \n",
    "parameters = {'cbc__verbose': ([False]),\n",
    "              'cbc__iterations': ([200]),\n",
    "              'cbc__class_weights':([(1, 1), (1, 11)])} #вот вообще не уверена, что class_weights тут нужен\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train_resample, target_train_resample)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "cbc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 CatBoostClassifier =', round(cbc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "cbc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 CatBoostClassifier на валидации =', round(cbc_valid_f1,2))\n",
    "print()\n",
    "\n",
    "#тестирование:\n",
    "predictions_test = gscv.predict(features_test.text)\n",
    "cbc_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('финальный F1 CatBoostClassifier =', round(cbc_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729fe85",
   "metadata": {},
   "source": [
    "### 3.4. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "004afa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 случайного леса = 0.77\n",
      "при параметрах {'rfc__class_weight': 'balanced', 'rfc__criterion': 'entropy', 'rfc__max_depth': 9, 'rfc__n_estimators': 29, 'rfc__random_state': 12345}\n",
      "\n",
      "F1 случайного леса на валидации = 0.33\n",
      "\n",
      "финальный F1 случайного леса = 0.33\n",
      "CPU times: user 11.3 s, sys: 8.13 s, total: 19.4 s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"rfc\", RandomForestClassifier())])\n",
    "    \n",
    "parameters = {'rfc__n_estimators': ([x for x in range(10, 30)]),\n",
    "              'rfc__random_state': ([12345]),\n",
    "              'rfc__max_depth': ([x for x in range(1, 10)]),\n",
    "              'rfc__criterion': (['entropy']),\n",
    "              'rfc__class_weight': (['balanced'])}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train_resample, target_train_resample)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "rfc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 случайного леса =', round(rfc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "rfc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 случайного леса на валидации =', round(rfc_valid_f1,2))\n",
    "print()\n",
    "\n",
    "#тестирование:\n",
    "predictions_test = gscv.predict(features_test.text)\n",
    "rfc_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('финальный F1 случайного леса =', round(rfc_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12910304",
   "metadata": {},
   "source": [
    "### 3.5. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1975c744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SGDClassifier = 0.89\n",
      "при параметрах {'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__learning_rate': 'adaptive', 'clf__loss': 'modified_huber', 'clf__random_state': 12345}\n",
      "\n",
      "F1 SGDClassifier на валидации = 0.69\n",
      "\n",
      "финальный F1 SGDClassifier = 0.7\n",
      "CPU times: user 8.22 s, sys: 2.95 s, total: 11.2 s\n",
      "Wall time: 38.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"clf\", SGDClassifier())])\n",
    "    \n",
    "parameters = {'clf__loss': ('hinge', 'log', 'modified_huber'),\n",
    "              'clf__learning_rate': ('constant', 'optimal', 'invscaling', 'adaptive'),\n",
    "              'clf__eta0': (.01, .05, .1, .5),\n",
    "              'clf__random_state': ([12345]),\n",
    "              'clf__class_weight': (['balanced'])}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train_resample, target_train_resample)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "sgdc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 SGDClassifier =', round(sgdc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "sgdc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 SGDClassifier на валидации =', round(sgdc_valid_f1,2))\n",
    "print()\n",
    "\n",
    "#тестирование:\n",
    "predictions_test = gscv.predict(features_test.text)\n",
    "sgdc_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('финальный F1 SGDClassifier =', round(sgdc_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9063d8d",
   "metadata": {},
   "source": [
    "### 3.6. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82423c97",
   "metadata": {},
   "source": [
    "сделала в colab - https://colab.research.google.com/drive/16XAF2PWGDozsRowdX2Z7asEhEClt1Xuc?usp=sharing,\n",
    "результаты не внесла в итоговую таблицу, так как F1 тоже < 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9cbeb",
   "metadata": {},
   "source": [
    "## 4. Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c24650b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на обучающей выборке</th>\n",
       "      <th>F1 на валидационной выборке</th>\n",
       "      <th>F1 на тестовой выборке (финальный)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.756038</td>\n",
       "      <td>0.764114</td>\n",
       "      <td>0.764640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.722311</td>\n",
       "      <td>0.722698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.891635</td>\n",
       "      <td>0.694762</td>\n",
       "      <td>0.697514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.712531</td>\n",
       "      <td>0.622162</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.773776</td>\n",
       "      <td>0.334877</td>\n",
       "      <td>0.332890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 на обучающей выборке  F1 на валидационной выборке  \\\n",
       "LogisticRegression                     0.756038                     0.764114   \n",
       "CatBoostClassifier                     0.872809                     0.722311   \n",
       "SGDClassifier                          0.891635                     0.694762   \n",
       "DecisionTreeClassifier                 0.712531                     0.622162   \n",
       "RandomForestClassifier                 0.773776                     0.334877   \n",
       "\n",
       "                        F1 на тестовой выборке (финальный)  \n",
       "LogisticRegression                                0.764640  \n",
       "CatBoostClassifier                                0.722698  \n",
       "SGDClassifier                                     0.697514  \n",
       "DecisionTreeClassifier                            0.612903  \n",
       "RandomForestClassifier                            0.332890  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаю сводную таблицу по показателям F1, времени обучения модели и времени предсказания модели:\n",
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'CatBoostClassifier',\n",
    "         'RandomForestClassifier',\n",
    "         'SGDClassifier'\n",
    "        ]\n",
    "\n",
    "data = {'F1 на обучающей выборке': [lr_train_f1,\n",
    "                                    dtc_train_f1,\n",
    "                                    cbc_train_f1,\n",
    "                                    rfc_train_f1,\n",
    "                                    sgdc_train_f1],\n",
    "        \n",
    "        'F1 на валидационной выборке': [lr_valid_f1,\n",
    "                                        dtc_valid_f1,\n",
    "                                        cbc_valid_f1,\n",
    "                                        rfc_valid_f1,\n",
    "                                        sgdc_valid_f1],\n",
    "        \n",
    "        'F1 на тестовой выборке (финальный)': [lr_test_f1,\n",
    "                                               dtc_test_f1,\n",
    "                                               cbc_test_f1,\n",
    "                                               rfc_test_f1,\n",
    "                                               sgdc_test_f1]}\n",
    "\n",
    "f1_data = pd.DataFrame(data=data, index=index)\n",
    "\n",
    "f1_data.sort_values(by='F1 на тестовой выборке (финальный)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ae963",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "В проекте:\n",
    "1. загрузила данные и провела их предобработку - удаление лишних данных, очистку текстов, лемматизацию \n",
    "2. обучила 4 модели с разными гиперпараметрами и выборками и проверила их на тестовой выборке\n",
    "3. выбрала лучшую модель по показателю F1\n",
    "\n",
    "Аутсайдером среди моделей стали RandomForestClassifier и DecisionTreeClassifier, так как дали наименьшее F1. \n",
    "\n",
    "Наилучшей моделью стала LogisticRegression, которая на тестировании показала F1 = 0.76. Поскольку требовалось найти модель классификации комментариев на позитивные и негативные со значением метрики качества F1 >= 0.75, рекомендовать могу LogisticRegression"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2852,
    "start_time": "2022-09-16T14:22:59.362Z"
   },
   {
    "duration": 3478,
    "start_time": "2022-09-16T14:23:02.216Z"
   },
   {
    "duration": 355,
    "start_time": "2022-09-16T14:23:05.696Z"
   },
   {
    "duration": 16,
    "start_time": "2022-09-16T14:23:06.054Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-16T14:23:06.072Z"
   },
   {
    "duration": 106011,
    "start_time": "2022-09-16T14:23:06.079Z"
   },
   {
    "duration": 15,
    "start_time": "2022-09-16T14:24:52.093Z"
   },
   {
    "duration": 21892,
    "start_time": "2022-09-19T19:18:03.648Z"
   },
   {
    "duration": 50,
    "start_time": "2022-09-21T12:39:00.011Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.062Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.064Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.064Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.066Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-21T12:39:00.067Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.075Z"
   },
   {
    "duration": 8,
    "start_time": "2022-09-21T12:39:00.092Z"
   },
   {
    "duration": 22,
    "start_time": "2022-09-21T12:39:00.102Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.126Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.127Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.128Z"
   },
   {
    "duration": 77,
    "start_time": "2022-09-21T12:39:00.191Z"
   },
   {
    "duration": 72,
    "start_time": "2022-09-21T12:39:00.270Z"
   },
   {
    "duration": 90,
    "start_time": "2022-09-21T12:39:00.344Z"
   },
   {
    "duration": 99,
    "start_time": "2022-09-21T12:39:00.435Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-21T12:39:00.535Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-21T12:39:00.546Z"
   },
   {
    "duration": 1750,
    "start_time": "2022-09-21T12:39:40.427Z"
   },
   {
    "duration": 2337,
    "start_time": "2022-09-21T12:39:42.179Z"
   },
   {
    "duration": 296,
    "start_time": "2022-09-21T12:39:44.518Z"
   },
   {
    "duration": 18,
    "start_time": "2022-09-21T12:39:44.817Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-21T12:39:44.837Z"
   },
   {
    "duration": 3634,
    "start_time": "2022-09-21T12:39:44.844Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-21T12:39:48.480Z"
   },
   {
    "duration": 50,
    "start_time": "2022-09-21T12:40:04.411Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-21T12:40:08.439Z"
   },
   {
    "duration": 31,
    "start_time": "2022-09-21T12:40:11.918Z"
   },
   {
    "duration": 204,
    "start_time": "2022-09-21T12:40:48.559Z"
   },
   {
    "duration": 616,
    "start_time": "2022-09-21T12:41:02.899Z"
   },
   {
    "duration": 3,
    "start_time": "2022-09-21T12:45:03.906Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-21T12:45:58.158Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-21T12:46:43.104Z"
   },
   {
    "duration": 617,
    "start_time": "2022-09-21T12:48:47.725Z"
   },
   {
    "duration": 67,
    "start_time": "2022-09-21T12:50:27.990Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-21T12:51:59.442Z"
   },
   {
    "duration": 27430,
    "start_time": "2022-09-21T12:52:12.091Z"
   },
   {
    "duration": 1824,
    "start_time": "2022-09-21T12:53:05.072Z"
   },
   {
    "duration": 736,
    "start_time": "2022-09-21T12:53:06.898Z"
   },
   {
    "duration": 282,
    "start_time": "2022-09-21T12:53:07.636Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-21T12:53:07.920Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-21T12:53:07.933Z"
   },
   {
    "duration": 3608,
    "start_time": "2022-09-21T12:53:07.944Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-21T12:53:11.554Z"
   },
   {
    "duration": 33,
    "start_time": "2022-09-21T12:53:20.690Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-21T12:53:24.402Z"
   },
   {
    "duration": 33,
    "start_time": "2022-09-21T12:53:25.567Z"
   },
   {
    "duration": 2,
    "start_time": "2022-09-21T12:53:40.136Z"
   },
   {
    "duration": 1200734,
    "start_time": "2022-09-21T12:54:43.963Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
